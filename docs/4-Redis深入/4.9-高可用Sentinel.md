# 高可用Sentinel
Sentinel（哨兵节点）可用于主从复制模式下，Master故障时Slave自动提升为Master。

## Sentinel作用
Sentinel主要有以下作用：
- 监控

    检测Master与Slave是否正常工作
- 通知

    当监控的Redis实例出现故障时，执行通知功能（可订阅其状态变化信息）
- 自动化failover
    
    Master故障时，Sentinel 会开始一次自动故障迁移操作，将某个Slave自动提升为Master，并将其它Slaves改为复制新的Master（这些Slaves以前的数据怎么办？）。
- 配置中心
    
    客户端直接连接到Sentinels（避免单点故障，这里应为多个），以获取到Master地址，当产生了failover时，Sentinels会报告新的地址。
  
### Master状态
Master包括三种状态：正常（master）、主观下线（s_down）、客观下线（o_down）

#### 主观下线

##### 主观下线的判定
当任一Sentinel在 `is-master-down-after-milliseconds` 内没有收到Master的回应时，将Master置为主观下线状态。

Sentinel通过Ping命令去检测Master状态，可接受的回应有以下三种：
1. +PONG
2. -LOADING error
3. -MASTERDOWN error

当不是这三种回应时，该Sentinel认为Master处于主观下线状态。

主观下线不会触发failover。

#### 客观下线

1. 当超过 `quorum` 数量的Sentinel均认Master主观下线时，Master客观下线。

2. 通过非强一致性算法（gossip）实现从主观下线到客观下线状态的转变：
    > 1. 当某个Sentinel认为Master主观下线时，这个Sentinel将会对其它Sentinel使用`SENTINEL is-master-down-by-addr` 命令来确定其它Sentinel对Master状态的判定，
    > 2. 当在给定时间内，达到 `quorum` 数量的Sentinel均认为Master客观下线时，Master的状态由主观下线变为客观下线
    > 3. 为Master下线的这些Sentinel中其中一个会申请执行failover
3. 客观下线会触发failover申请，但是否通过取决于“大多数原则”
    > 1. Sentinel使用投票协议（agreement protocols）来决定是否执行自动故障迁移（达到大多数才可执行failover）;
    > 2. Sentinel会记住已发现的其它Sentinel，因此即使Sentinel之间通信失败或某个Sentinel crash，也会不影响其它Sentinel对Sentinels总数的判定
4. 只有Master拥有客观下线状态，Slave与Sentinel只拥有主观下线状态
    > Slave的主观下线状态的意义在于：在某个Sentinel执行failover的过程中，不会选举主观下线状态的Slave为Master
    
    
## 配置项
- 可用redis-sentinel启动Sentinel `redis-sentinel /path/to/sentinel.conf`，其中配置文件为必须项且可写
    > Sentinel会将当前状态信息（如Slaves信息、failover后新的Master）修改到这个配置文件中
- Sentinel默认使用TCP端口26379

### 简单配置
```
port 5000
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel auth-pass mymaster foobared
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1
```
- port 5000

    Sentinel启动端口
- sentinel monitor

    比如：`sentinel monitor mymaster 127.0.0.1 6379 2`
    1. 只需要配置master地址，slaves会自动发现，同时还需要给master取个“名称”，即这里的 `mymaster`。
被发现的slaves会被自动添加到这个配置文件中，同时当出现failover时，信息也会被记录。
    2. 当达到2个sentinel认为master故障时，其中一个sentinel将当前Master标记为故障，并尝试执行failover，
    当对这个sentinel来说有超过半数的sentinel（包括自己）可达时，将会开始执行failover
    3. 可使用 `sentinel master mymaster` 检查当前master状态
- down-after-milliseconds

    当Sentinel在超过这个时间没有收到Master的回应时，则Sentinel认为Master不可用
- parallel-syncs

    failover时，新master可同时向多少个slave进行数据同步（这个值越小，failover所花时间越多）
    
#### 自动发现
上面Sentinel并未配置其它Sentinel及Slave的地址，这是因为Sentinel可以基于“自动发现”机制找到其它Sentinel及Slave。
##### 自动发现Sentinel
1. Sentinel会每2秒一次，向其监控的Master中的 `__sentinel__:hello` 频道发送信息，报告自己的ip, port, runid。
2. Sentinel也会订阅这个频道：  `__sentinel__:hello` 以获取其它的Sentinel信息以及Master的配置信息（如果Sentinel发现接收到Master配置信息要更新一点，Sentinel也会因此更新自己的配置）
##### 自动发现Slave
Master掌握了所有Slave信息，配置了Master地址，也就知道了所有的Slave

### 配置管理
Sentinel会管理Redis实例（Master + Slave）的配置。
1. 当某个Redis实例认为自己是Master（根据自己的配置），而Sentinel认为这个Redis实例是Slave（根据从Sentinel的配置）时，Sentinel会将这个Redis实例重新配置为Slave。
2. 当某个Slave对应的Master（根据自己的配置）与Sentinel记录不符时，Sentinel也会以自己的记录重新配置Slave。
3. Masters failed over are reconfigured as replicas when they return available.
4. Replicas partitioned away during a partition are reconfigured once reachable.

## Master选举
当达到failover条件后，某一个Sentinel将会来执行failover，选举一个Slave作为新的Master
    
### 其它配置
- requirepass foobared

    从Redis 5.0.1开始，Sentinel也可以配置密码。Sentinel也会用这个密码去和其它Sentinel通信，因此**每个Sentinel的密码必须一致**。

### 监视多个Master
Sentinel 也可以监视多个Master，如：
```
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1

sentinel monitor resque 192.168.1.3 6380 4
sentinel down-after-milliseconds resque 10000
sentinel failover-timeout resque 180000
sentinel parallel-syncs resque 5
```

## 配置示例
- M: Master
- R: Replication(Slave)
- S: sentinel
- B： Box（这里可表示一个computer或VM）
### 一主两从三哨兵
```
       +-B1-+
       | M1 |
       | S1 |
       +----+
          |
+-B2-+    |    +-B3-+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+

Configuration: quorum = 2
```

#### 异常情况
- Sentinel网络分区

    当B1产生网络分区后（B1不能与B2,B3通信），S2, S3选举出新的Master，但这里S1仍认为Master为M1（同时有部分客户端C1仍认为Master为M1），
    当网络分区恢复后，M1抛弃所有数据并成为Slave（因此这段时间内C1往M1写的数据会丢失）
    可使用如下配置减轻这种情况：
    ```
    min-replicas-to-write 1
    min-replicas-max-lag 10
    ```
    在这种配置下，当B1产生网络分区，达不到 `min-replicas-to-write 1` 这个条件，因此C1无法往Master中写数据
    
### 客户端配置Sentinel
```
     +-B1-+         +-B2-+
     | M1 |----+----| R1 |
     |    |    |    |    |
     +----+    |    +----+
               |
  +------------+------------+
  |            |            |
  |            |            |
+-B3-+       +-B4-+      +-B5-+
| C1 |       | C2 |      | C3 |
| S1 |       | S2 |      | S3 |
+----+       +----+      +----+

Configuration: quorum = 2
```

## 成员变更
### 添加Sentinel
在启动一个Sentinel实例时，只需要配置需要监控的Master，这个Sentinel就会通过“自动发现”策略（在10秒内）嗅探到其它的Sentinel及Slave。
> 因此添加Sentinel时，只需要启动这个Sentinel并监控同样的Master就行了；但当需要添加多个新的Sentinel时，建议一个一个地加，
防止在添加Sentinel时发生failover。

### 移除Sentinel
由于**Sentinel会记住已发现的Sentinel（即使这个Sentinel很长时间不可达）。**
可在没有网络分区的情况下依次在每个Sentinel上执行命令：`SENTINEL RESET mastername`（注意需要等待至少三十秒再执行下一个）。最后可以通过 
`SENTINEL MASTER mastername`检查结果中的`num-other-sentinels`是否正确。

### 移除Slave
**Sentinel同样会记住已发现的Slave（即使Slave很长时间不可达）。**
同样可依次再每个Sentinel上执行命令： `SENTINEL RESET mastername`，这时Sentinel会从Master的INFO命令中获取当前的所有Slave。


## Sentinel监控
### 状态检查
1. 检查Master  `sentinel master mymaster`
2. 检查Slaves  `sentinel slaves mymaster`
3. 检查Sentinels  `sentinel sentinels mymaster`
4. 获取Master地址 `SENTINEL get-master-addr-by-name mymaster`

### 事件订阅
可使用SUBSCRIBE命令订阅状态的改变，如： `SUBSCRIBE *`可订阅所有事件，事件见下：
```
+reset-master <instance details> -- The master was reset.
+slave <instance details> -- A new replica was detected and attached.
+failover-state-reconf-slaves <instance details> -- Failover state changed to reconf-slaves state.
+failover-detected <instance details> -- A failover started by another Sentinel or any other external entity was detected (An attached replica turned into a master).
+slave-reconf-sent <instance details> -- The leader sentinel sent the SLAVEOF command to this instance in order to reconfigure it for the new replica.
+slave-reconf-inprog <instance details> -- The replica being reconfigured showed to be a replica of the new master ip:port pair, but the synchronization process is not yet complete.
+slave-reconf-done <instance details> -- The replica is now synchronized with the new master.
-dup-sentinel <instance details> -- One or more sentinels for the specified master were removed as duplicated (this happens for instance when a Sentinel instance is restarted).
+sentinel <instance details> -- A new sentinel for this master was detected and attached.
+sdown <instance details> -- The specified instance is now in Subjectively Down state.
-sdown <instance details> -- The specified instance is no longer in Subjectively Down state.
+odown <instance details> -- The specified instance is now in Objectively Down state.
-odown <instance details> -- The specified instance is no longer in Objectively Down state.
+new-epoch <instance details> -- The current epoch was updated.
+try-failover <instance details> -- New failover in progress, waiting to be elected by the majority.
+elected-leader <instance details> -- Won the election for the specified epoch, can do the failover.
+failover-state-select-slave <instance details> -- New failover state is select-slave: we are trying to find a suitable replica for promotion.
no-good-slave <instance details> -- There is no good replica to promote. Currently we'll try after some time, but probably this will change and the state machine will abort the failover at all in this case.
selected-slave <instance details> -- We found the specified good replica to promote.
failover-state-send-slaveof-noone <instance details> -- We are trying to reconfigure the promoted replica as master, waiting for it to switch.
failover-end-for-timeout <instance details> -- The failover terminated for timeout, replicas will eventually be configured to replicate with the new master anyway.
failover-end <instance details> -- The failover terminated with success. All the replicas appears to be reconfigured to replicate with the new master.
switch-master <master name> <oldip> <oldport> <newip> <newport> -- The master new IP and address is the specified one after a configuration change. This is the message most external users are interested in.
+tilt -- Tilt mode entered.
-tilt -- Tilt mode exited.
```

    
## 其它
- Sentinel应该为至少为独立的三个，主要有以下原因：
    - 当多个Sentinel认为Master不可用时，才执行failure detection
    - 避免Sentinel出现单点故障
- Redis 2.6发布了第一个版本的Sentinel（已废弃），2.8发布了第二个版本的Sentinel
- 由于Redis采用异步复制，因此Sentinel + Redis这种高可用也并不能保证failover后数据不丢失，参考：[主从复制数据一致性](/4-Redis深入/4.8-主从复制.md#数据一致性问题)
    1. 原Master的操作记录还并未同步到提升为Master的Slave节点
    2. 原Master与Slave之间产生网络分区（需要一定时间才能确定网络分区的产生），Master的操作记录无法同步到Slave
- 客户端也应该支持Sentinel
- 可在Sentinel运行时使用 `SENTINEL SET` 命令修改Sentinel相关配置
- 使用 `redis-cli -p 6379 DEBUG sleep 30` 可以使用Redis server停止服务30秒
- 可利用 `replica-priority` Slave被选举为Master的权重
    > 0表示不能被选举为Master
    > 数值越小越容易被选举为Master
- Master与Slave的密码项（requirepass、masterauth）应保存一致，因为Slave也可能会被选举为Master
